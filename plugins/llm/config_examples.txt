# LLM Plugin Configuration Examples

## Environment Variables
export LLM_API_KEY="your-openai-or-claude-api-key"

## OpenAI Configuration Examples

### Basic GPT-3.5 Turbo
./llm --api-key $LLM_API_KEY --provider openai --model gpt-3.5-turbo

### GPT-4 with custom settings
./llm \
  --api-key $LLM_API_KEY \
  --provider openai \
  --model gpt-4 \
  --temperature 0.3 \
  --max-tokens 1000 \
  --stop-words "END,STOP,COMPLETE"

### GPT-4 Turbo for faster responses
./llm \
  --api-key $LLM_API_KEY \
  --provider openai \
  --model gpt-4-turbo \
  --temperature 0.5 \
  --max-tokens 800

## Claude Configuration Examples

### Claude 3 Sonnet
./llm --api-key $LLM_API_KEY --provider claude --model claude-3-sonnet-20240229

### Claude 3 Opus (most capable)
./llm \
  --api-key $LLM_API_KEY \
  --provider claude \
  --model claude-3-opus-20240229 \
  --temperature 0.2 \
  --max-tokens 1500

### Claude 3 Haiku (fastest)
./llm \
  --api-key $LLM_API_KEY \
  --provider claude \
  --model claude-3-haiku-20240307 \
  --temperature 0.7 \
  --max-tokens 500

## Custom Prompt Template Examples

### Security-focused template
./llm \
  --api-key $LLM_API_KEY \
  --provider openai \
  --prompt-file ./security_analysis_prompt.txt

### Incident response template
./llm \
  --api-key $LLM_API_KEY \
  --provider claude \
  --prompt-file ./incident_response_prompt.txt

## Docker Environment Variables

### docker-compose.yml addition
services:
  llm-plugin:
    build: ./plugins/llm
    environment:
      - LLM_API_KEY=${LLM_API_KEY}
      - REDIS_URL=redis://redis:6379
    command: >
      ./llm
      --redis redis://redis:6379
      --provider openai
      --model gpt-3.5-turbo
      --temperature 0.7
    depends_on:
      - redis

## Systemd Service Example

### /etc/systemd/system/console-ir-llm.service
[Unit]
Description=Console-IR LLM Plugin
After=network.target redis.service

[Service]
Type=simple
User=console-ir
WorkingDirectory=/opt/console-ir
Environment=LLM_API_KEY=your-api-key-here
ExecStart=/opt/console-ir/bin/llm \
  --redis redis://localhost:6379 \
  --provider openai \
  --model gpt-3.5-turbo \
  --temperature 0.7 \
  --max-tokens 800
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target

## Performance Tuning

### High-throughput (faster, less detailed)
./llm \
  --api-key $LLM_API_KEY \
  --provider openai \
  --model gpt-3.5-turbo \
  --temperature 0.1 \
  --max-tokens 300

### High-quality analysis (slower, more detailed)
./llm \
  --api-key $LLM_API_KEY \
  --provider claude \
  --model claude-3-opus-20240229 \
  --temperature 0.3 \
  --max-tokens 2000

## Cost Optimization

### Budget-friendly OpenAI
./llm \
  --api-key $LLM_API_KEY \
  --provider openai \
  --model gpt-3.5-turbo \
  --max-tokens 200

### Budget-friendly Claude
./llm \
  --api-key $LLM_API_KEY \
  --provider claude \
  --model claude-3-haiku-20240307 \
  --max-tokens 300
